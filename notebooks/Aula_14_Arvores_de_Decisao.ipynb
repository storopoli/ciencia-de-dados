{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/storopoli/ciencia-de-dados/master?filepath=notebooks%2FAula_14_Arvores_de_Decisao.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Árvores de Decisão (*Decision Trees*)\n",
    "\n",
    "**Objetivos**: Aprender o que é Árvores de Decisão usando a biblioteca `Scikit-Learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## O que é uma Árvore de Decisão?\n",
    "\n",
    "Uma árvore de decisão é uma estrutura do tipo fluxograma na qual cada nó interno representa um \"teste\" em um atributo (por exemplo, se um lançamento de moeda aparece cara ou coroa), cada ramo representa o resultado do teste e cada nó folha representa um rótulo de classe (decisão tomada após o cálculo de todos os atributos). Os caminhos da raiz para a folha representam regras de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Elementos de uma Árvore de Decisão\n",
    "\n",
    "* **Árvore** (*Tree*): Mapeamento de uma decisão composta por nós e folhas\n",
    "* **Nó de Decisão** (*Node*): Quando um nó se divide em outros sub-nós, ele é chamado de nó de decisão\n",
    "* **Raiz** (*Root*): Primeiro nó de decisão\n",
    "* **Folha** (*Leaf*): Os nós não divididos são chamados de nó folha\n",
    "\n",
    "<img src=\"images/arvore-decisao.jpg\" alt=\"arvore-decisao\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Impureza de Nós - Classificação\n",
    "\n",
    "* Um nó é puro quando todas as observações que ele se aplica decisões são da mesma classe.\n",
    "* Quanto menor mais puro o nó\n",
    "* Mensurado por\n",
    "\t* Índice de Gini: Menor custo computacional\n",
    "\t* Entropia: Maior custo computacional\n",
    "\t* Na maioria das vezes não faz diferença Gini ou Entropia.\n",
    "\t\t* Mas quando há diferença, Entropia tende a gerar árvores mais equilibradas\n",
    "        \n",
    "## Impureza de Nós - Regressão\n",
    "\n",
    "* Um nó é puro quando todas as observações que ele se aplica decisões possuem erro zero.\n",
    "* Quanto menor mais puro o nó\n",
    "* Mensurado por\n",
    "\t* MSE: Maior punição para erros \"grosseiros\"\n",
    "\t* MAE: Punição igual para todos os erros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Classificação e Regressão\n",
    "\n",
    "* Classificação: [`sklearn.tree.DecisionTreeClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "* Regressão: [`sklearn.tree.DecisionTreeRegressor()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hiperparâmetros\n",
    "\n",
    "* **Profundidade Máxima das Árvores**: Número mínimo de folhas que devem existir em uma dada árvore\n",
    "* **Quantidade Mínima de Observações para uma Decisão**: Mínimo de Amostra que um Nó deve ter para ser separado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemplo com o Dataset Titanic\n",
    "\n",
    "Contém 891 passageiros reais do Titanic que afundou em 15/04/1912 matando 1502 de 2224 passageiros e tripulação que estavam a bordo.\n",
    "\n",
    "* `survived`: *dummy* `0` ou `1` \n",
    "* `pclass`: Classe do Passageiro\n",
    "    - `1`: Primeira Classe\n",
    "    - `2`: Segunda Classe\n",
    "    - `3`: Terceira Classe\n",
    "* `sex`: Sexo `male` ou `female`\n",
    "* `age`: Idade\n",
    "* `sibsp`: Número de Irmãos (*Siblings*) e Esposas (*spouse*) a bordo\n",
    "* `parch`: Número de pais/filhos a bordo\n",
    "* `fare`: Valor pago pela passagem em libras\n",
    "* `embarked`: Porto que embarcou\n",
    "    - `C`: Cherbourg\n",
    "    - `Q`: Queenstown\n",
    "    - `S`: Southampton)\n",
    "* `class`: Mesmo que `pclass` só que em texto\n",
    "* `adult_male`: *dummy* para `age > 16` e `sex == 'male'`\n",
    "* `deck`: Qual deck a cabine do passageiro se situava\n",
    "* `alive`: Mesmo que survived só que com `yes` ou `no`\n",
    "* `alone`: *dummy* para se viajava sozinho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/titanic.png\" alt=\"titanic\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "feature_names = ['pclass', 'female', 'age', 'fare']\n",
    "titanic['female'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "titanic.dropna(subset=feature_names, inplace=True)  #891 para 714\n",
    "\n",
    "X = titanic[feature_names].to_numpy()\n",
    "y = titanic['survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Árvore de Classificação\n",
    "Usar a função do Scikit-Learn [`sklearn.tree.DecisionTreeClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "#### Argumentos:\n",
    "* `criterion` - `str` - Critério de Impureza (Gini ou Entropia)\n",
    "    * `'gini'` - padrão\n",
    "    * `'entropy'`\n",
    "* `max_depth` - `int` - Profundidade Máxima da Árvore\n",
    "* `min_samples_split` - `int` ou `float` - Quantidade Mínima de Observações para uma Decisão\n",
    "* `min_samples_leaf` - `int` ou `float` - Quantidade Mínima de Observações para que um Nó vire Folha (não tenha mais outros nós abaixo)\n",
    "* `random_state` - `int` - seed do gerador de número randômicos (replicabilidade)\n",
    "\n",
    "#### Retorna:\n",
    "* Objeto `estimator` do Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Árvore de Regressão\n",
    "Usar a função do Scikit-Learn [`sklearn.tree.DecisionTreeRegressor()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "#### Argumentos:\n",
    "* `criterion` - `str` - Critério de Impureza (MSE ou MAE)\n",
    "    * `'mse'` - padrão\n",
    "    * `'mae'`\n",
    "* `max_depth` - `int` - Profundidade Máxima da Árvore\n",
    "* `min_samples_split` - `int` ou `float` - Quantidade Mínima de Observações para uma Decisão\n",
    "* `min_samples_leaf` - `int` ou `float` - Quantidade Mínima de Observações para que um Nó vire Folha (não tenha mais outros nós abaixo)\n",
    "* `random_state` - `int` - seed do gerador de número randômicos (replicabilidade)\n",
    "\n",
    "#### Retorna:\n",
    "* Objeto `estimator` do Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=123)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Acurácia do Modelo\n",
    "Usar a função do Scikit-Learn [`sklearn.metrics.accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "\n",
    "Retorna um score de acurácia `float` entre $0$ e $1$\n",
    "\n",
    "#### Argumentos\n",
    "* `y_true`: Classes Verdadeiras\n",
    "    * 2 classes: vetor (1-D)\n",
    "    * Mais que 2 classes: matriz (2-D)\n",
    "* `y_pred`: Classes Previstas pelo Modelo\n",
    "    * 2 classes: vetor (1-D)\n",
    "    * Mais que 2 classes: matriz (2-D)\n",
    "    \n",
    "> Obs: Regressão Logística acurácias: 0.69 Treino e 0.7 Teste\n",
    "\n",
    "> Obs: *Support Vector Machines* acurácias: 0.79 Treino e 0.75 Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_true = y_train\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_true = y_test\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Acurácia de Treino: {round(accuracy_score(y_train_true, y_train_pred), 2)}\")\n",
    "print('\\n ---------------------------\\n')\n",
    "print(f\"Acurácia de Teste: {round(accuracy_score(y_test_true, y_test_pred), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plotando a Árvore\n",
    "\n",
    "Usar a função do Scikit-Learn [`sklearn.tree.plot_tree()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html). Usar junto com o `matplotlib.pyplot`.\n",
    "\n",
    "Lembrando nossos features\n",
    "\n",
    "* `X[0]` = `'pclass'`\n",
    "* `X[1]` = `'female'`\n",
    "* `X[2]` = `'age'`\n",
    "* `X[3]` = `'fare'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure()\n",
    "plot_tree(clf, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![mapa-conceitual](https://raw.githubusercontent.com/storopoli/ciencia-de-dados/master/Mapas%20Conceituais/15%20-%20Arvores%20de%20Decisao.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Atividade - Árvores de Decisão com o dataset [Iris](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset)\n",
    "\n",
    "Edgar Anderson coletou os dados para quantificar a variação morfológica das flores de íris de três espécies relacionadas.\n",
    "\n",
    "O conjunto de dados consiste em 50 amostras de cada uma das três espécies de Iris (Setosa, Virginica e Versicolor). Quatro características foram medidas em cada amostra (cm):\n",
    "\n",
    "* $N = 150$\n",
    "* Atributos: 10\n",
    "    * `sepal length (cm)` - Cumprimento da Sépala\n",
    "    * `sepal width (cm)` - Largura da Sépala\n",
    "    * `petal length (cm)` - Cumprimento da Pétala\n",
    "    * `petal width (cm)` - Largua da Sépala\n",
    "* Variável dependente: Tipo de espécie de Iris\n",
    "    * `0` - Setosa\n",
    "    * `1` - Virginica\n",
    "    * `2` Versicolor \n",
    "\n",
    "* Achar a acurácia do modelo e os respectivos coeficientes dos atributos ($\\theta_i$) e viés/constante ($\\theta_0$)\n",
    "\n",
    ">Obs: usar `test_size = 0.25` e `random_state = 123`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://thegoodpython.com/assets/images/iris-species.png\" alt=\"iris-sepals-petals\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Nomes dos Atributos: ', iris['feature_names'], '\\n')\n",
    "print('Tamanho de X: ', X.shape, '\\n')\n",
    "print('Tamanho de y: ', y.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Tamanho de X_train: ', X_train.shape, '\\n')\n",
    "print('Tamanho de X_test: ', X_test.shape, '\\n')\n",
    "print('Tamanho de y_train: ', y_train.shape, '\\n')\n",
    "print('Tamanho de y_test: ', y_test.shape, '\\n')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
